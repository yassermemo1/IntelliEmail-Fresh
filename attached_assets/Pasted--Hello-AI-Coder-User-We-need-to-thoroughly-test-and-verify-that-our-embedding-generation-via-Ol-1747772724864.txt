"Hello AI Coder / User,

We need to thoroughly test and verify that our embedding generation (via Ollama nomic-embed-text), storage in PostgreSQL/pgvector (as VECTOR(768)), indexing, and basic vector similarity search are all functioning correctly.

Project: AI-Powered Email Task Manager
Current Date for Context: Tuesday, May 20, 2025
Current Location Context: Riyadh, Saudi Arabia

Prerequisites:

Ollama is running on the host with nomic-embed-text model pulled and accessible (e.g., via http://localhost:11434).
PostgreSQL with pgvector extension (v0.5.1+) is running and the database schema includes embedding_vector VECTOR(768) columns in emails and tasks tables.
HNSW (or IVFFlat) indexes are defined on these vector columns.
Your FastAPI backend and RQ workers are running.
You have mechanisms to trigger email sync and processing (which should lead to embedding generation).
You have psql access to your PostgreSQL database and curl or a similar tool for API testing.
Testing & Verification Steps:

Step 1: Verify Ollama nomic-embed-text Output Directly (Manual Check)

Objective: Confirm nomic-embed-text via Ollama produces 768-dimensional vectors.
Action (User):
Open a terminal on your host machine where Ollama is running.
Run the following curl command:
Bash
curl http://localhost:11434/api/embeddings -d '{
  "model": "nomic-embed-text",
  "prompt": "This is a test sentence."
}'
Expected Output: A JSON response containing an "embedding" array.
Verification (User):
Does the response contain an "embedding" key with an array of numbers?
Manually count (or use a script to count) the number of elements in this array. Is it 768?
Report (User to paste output): Paste the JSON response from Ollama.
Step 2: Verify Embedding Generation and Storage for a New Email (End-to-End)

Objective: Confirm that when a new email is processed, a 768-dimensional embedding is generated by Ollama (via NlpService) and stored correctly in the emails.embedding_vector column.
Action (User):
Ensure RQ workers (especially nlp queue) are running.
Send a new, unique test email to your connected Gmail account (the one using IMAP/App Password).
Allow a few minutes for the email to be synced and processed by the RQ pipeline.
Identify the id (UUID) or provider_email_id of this newly synced email in your emails table.
Verification (User, using psql):
AI Coder to provide specific psql query: "Please provide a psql query to fetch the embedding_vector for a specific email ID and a way to check its dimension within psql."
(Likely query from AI Coder for user to run):
SQL
-- Replace 'YOUR_NEW_EMAIL_ID_HERE' with the actual ID
SELECT 
    id, 
    subject, 
    embedding_vector IS NOT NULL AS has_embedding,
    array_length(embedding_vector::real[], 1) AS embedding_dimension 
FROM emails 
WHERE id = 'YOUR_NEW_EMAIL_ID_HERE'; 
-- OR use provider_email_id if easier to find
-- WHERE provider_email_id = 'PROVIDERS_UNIQUE_ID_FOR_NEW_EMAIL'; 
Expected Output:
has_embedding should be true.
embedding_dimension should be 768.
Report (User to paste output): Paste the psql query result.
AI Coder Action (if issues): If has_embedding is false or dimension is wrong, investigate NlpService, generate_embedding_for_email RQ job, and Ollama interaction logs.
Step 3: Verify Embedding Generation and Storage for a New Task (End-to-End)

Objective: Confirm that when a new task is created (e.g., from the email processed in Step 2), a 768-dimensional embedding is generated and stored correctly in tasks.embedding_vector.
Prerequisites: Step 2 was successful, and the AI feature extraction and task generation pipeline ran for that new email.
Action (User):
Identify the id (UUID) of a task generated from the email in Step 2.
Verification (User, using psql):
AI Coder to provide specific psql query: "Please provide a psql query to fetch the embedding_vector for a specific task ID and check its dimension."
(Likely query from AI Coder for user to run):
SQL
-- Replace 'YOUR_NEW_TASK_ID_HERE' with the actual ID
SELECT 
    id, 
    title, 
    embedding_vector IS NOT NULL AS has_embedding,
    array_length(embedding_vector::real[], 1) AS embedding_dimension 
FROM tasks 
WHERE id = 'YOUR_NEW_TASK_ID_HERE';
Expected Output:
has_embedding should be true.
embedding_dimension should be 768.
Report (User to paste output): Paste the psql query result.
AI Coder Action (if issues): If has_embedding is false or dimension is wrong, investigate generate_embedding_for_task_record RQ job and its call to NlpService.
Step 4: Verify Basic Vector Similarity Search (pgvector Functionality)

Objective: Confirm that pgvector can perform a basic similarity search using the stored 768-dimensional embeddings.
Prerequisites: At least a few emails and tasks have embeddings stored (from Steps 2 & 3).
Action (User, using psql):
Get an actual embedding vector for one of your test emails (let's call it source_email_id and its embedding source_embedding_vector_text_representation). You can get this from:
SQL
SELECT embedding_vector::text FROM emails WHERE id = 'YOUR_SOURCE_EMAIL_ID_HERE';
(Copy the long array string output).
Run a similarity search. <!-- end list -->
AI Coder to provide specific psql query: "Please provide a psql query that uses a known embedding_vector from one email to find the top 3 most similar emails (including itself) from the emails table using cosine distance (<=> operator)."
(Likely query from AI Coder for user to run):
SQL
-- Replace 'YOUR_SOURCE_EMAIL_ID_HERE' with an actual ID of an email that HAS an embedding
-- Replace '[<COPIED_VECTOR_ARRAY_AS_TEXT>]' with the actual text representation of the vector
-- Ensure it's correctly formatted as a PostgreSQL array string if needed, e.g., '{0.1,0.2,...}'
-- Or, more robustly, use a subquery if psql handles it well:
WITH source_email AS (
    SELECT embedding_vector FROM emails WHERE id = 'YOUR_SOURCE_EMAIL_ID_HERE' LIMIT 1
)
SELECT 
    e.id, 
    e.subject, 
    (e.embedding_vector <=> (SELECT embedding_vector FROM source_email)) AS distance 
FROM emails e, source_email
WHERE e.embedding_vector IS NOT NULL AND e.connected_account_id = (SELECT connected_account_id FROM emails WHERE id = 'YOUR_SOURCE_EMAIL_ID_HERE') -- Scope search
ORDER BY distance ASC 
LIMIT 3;
Expected Output:
A list of 3 emails. The first one should be the source_email_id itself (with distance 0 or very close to 0). The other emails should be semantically related.
Report (User to paste output): Paste the psql query and its result.
AI Coder Action (if issues): If the query fails, or returns unexpected results, or the distances are all very high, investigate: * Correctness of HNSW index on emails.embedding_vector (was vector_cosine_ops used during index creation?). * Whether embeddings being stored are valid/normalized. * The query construction.
Step 5: Verify RAG Context Retrieval (Service Level)

Objective: Confirm the SemanticSearchService (or equivalent) correctly retrieves context for RAG using the vector embeddings.
Action (User/AI Coder - might need a test script or temporary API endpoint):
AI Coder to advise: "How can we easily test the SemanticSearchService.get_historical_context_for_email() function? Can you provide a small Python script or a temporary test API endpoint that calls this service with a specific email_id (one that has an embedding) and prints the retrieved contextual items (subjects/titles of related emails/tasks)?"
Verification:
Does the service return plausible related emails/tasks based on what you know is in your test data?
Report: Output of the test script/API call.
AI Coder Action (if issues): Debug the SemanticSearchService logic.
